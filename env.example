# LLM Backend Configuration
LLM_BACKEND=openai  # or ollama
TEMPERATURE=0.7

# OpenAI Configuration
OPENAI_API_KEY=your_key_here
OPENAI_MODEL_NAME=gpt-4o-mini  # Optional, defaults to gpt-4o-mini

# Ollama Configuration
OLLAMA_HOST=http://ollama:11434  # Optional, defaults to http://ollama:11434
OLLAMA_MODEL_NAME=mistral  # Optional, defaults to mistral

# ChromaDB Configuration
CHROMA_SERVER_HOST=localhost  # Optional, defaults to localhost
CHROMA_SERVER_HTTP_PORT=8000  # Optional, defaults to 8000

# Reddit API Configuration
REDDIT_CLIENT_ID=your_client_id
REDDIT_CLIENT_SECRET=your_client_secret

# FastAPI Configuration
API_PORT=3000  # Optional, defaults to 3000
